version: '2'

services:
  # Compute: HTTP API and task producer
  compute:
    build: ./compute-api
    restart: unless-stopped
    mem_limit: 50000000
    memswap_limit: 0
    command: -host 0.0.0.0 -port 80 -broker nsq -broker-host nsqd -broker-port 4150
    ports:
    - "${COMPUTE_PORT}:80/tcp"
    networks:
    - internal
    depends_on:
    - nsqd

  # Compute: task consumer
  compute-worker:
    build: ./compute-worker
    restart: unless-stopped
    mem_limit: 50000000
    memswap_limit: 0
    environment:
    - "DOCKER_HOST=tcp://dind-executor:2376"
    command: -nsqlookupd-urls "nsqlookupd:4161" -storage-host "storage" -learn-timeout 5m
    privileged: true
    networks:
    - internal
    volumes:
    - compute_datadir:/data
    depends_on:
    - nsqlookupd
    - dind-executor
    - orchestrator
    - storage

  # Docker-in-Docker container to run untrusted code
  dind-executor:
    build: ./utils/dind-daemon
    mem_limit: 1000000000
    memswap_limit: 0
    restart: unless-stopped
    privileged: true
    command: --host tcp://0.0.0.0:2376
    volumes:
    - compute_datadir:/data
    networks:
    - internal

  # Nsqlookupd: service discovery for Nsqd
  nsqlookupd:
    image: nsqio/nsq:latest
    mem_limit: 50000000
    memswap_limit: 0
    restart: unless-stopped
    command: /nsqlookupd
    networks:
    - internal
    depends_on:
    - nsqd

  # Nsqd: the distributed broker
  nsqd:
    image: nsqio/nsq:latest
    mem_limit: 50000000
    memswap_limit: 0
    restart: unless-stopped
    command: /nsqd --lookupd-tcp-address="nsqlookupd:4160"
    networks:
    - internal

  # Nsq Admin frontend
  nsqadmin:
    image: nsqio/nsq:latest
    mem_limit: 50000000
    memswap_limit: 0
    restart: unless-stopped
    command: /nsqadmin --lookupd-http-address="nsqlookupd:4161"
    networks:
    - internal
    ports:
    - "${NSQ_ADMIN_PORT}:4171/tcp"

  # Storage
  storage:
    build: ./storage-api
    restart: unless-stopped
    command: -host 0.0.0.0 -port 80 -user ${STORAGE_AUTH_USER} -password ${STORAGE_AUTH_PASSWORD}
    ## Stops the container from taking up all the cache memory on big file
    ## uploads
    mem_limit: 100000000
    memswap_limit: 100000000
    volumes:
    - ./data/storage:/data
    - /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt:ro
    ports:
    - "${STORAGE_PORT}:80/tcp"
    networks:
    - internal
    depends_on:
    - postgres

  # Postgres instance for the storage service
  postgres:
    image: postgres:alpine
    mem_limit: 200000000
    memswap_limit: 0
    volumes:
    - ./data/postgres:/var/lib/postgres
    environment:
    - POSTGRES_PASSWORD=tooshort
    - POSTGRES_USER=storage
    - POSTGRES_DB=morpheo_storage
    networks:
      - internal

  # Orchestrator
  orchestrator:
    image: registry.morpheo.io/orchestrator:latest
    mem_limit: 100000000
    memswap_limit: 0
    volumes:
    - ../morpheo-ochestrator/app/:/usr/src/app

    links:
    - mongodb
    entrypoint: ""
    command:
    - gunicorn
    - --config
    - gunicorn_config.py
    - api:app
    ports:
    - "${ORCHESTRATOR_PORT}:80/tcp"
    networks:
    - internal
    environment:
    - MONGO_HOST=mongodb
    - CORS=True
    - LISTEN_PORT=80
    - USER_AUTH=test
    - PWD_AUTH=test

  # MongoDB instance for the orchestrator
  mongodb:
    image: mongo:3.4
    mem_limit: 200000000
    memswap_limit: 0
    networks:
    - internal
    volumes:
    - ./data/mongo:/data/db

networks:
  # Accessible from the outside (a mock of what some call "the Internet")
  internal:
    driver: bridge

volumes:
  compute_datadir:
    driver: local
